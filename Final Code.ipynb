{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a92861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data visualization\n",
    "import matplotlib.pyplot as plt  # Matplotlib for plotting\n",
    "import seaborn as sns  # Seaborn for statistical data visualization\n",
    "\n",
    "# Import machine learning libraries\n",
    "from sklearn.ensemble import GradientBoostingRegressor  # Gradient Boosting Regressor\n",
    "import pandas as pd  # Pandas for data manipulation\n",
    "import numpy as np  # NumPy for numerical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e2eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Read the dataset into a Pandas DataFrame\n",
    "df = pd.read_csv('C:/Users/methu/OneDrive/Documents/4th sem/Capstone Project/Final Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea6581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the DataFrame to inspect the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba4a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide information about the DataFrame, including data types and missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed57e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-numeric characters from the \"Weighted salary\" column and convert it to float\n",
    "df[\"Weighted salary\"] = df[\"Weighted salary\"].str.replace('[^\\d.]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3335f9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of missing values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6dcc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of columns to impute with the median\n",
    "columns_to_impute = [\"GMAT/GRE Required\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b890b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in selected columns with the median\n",
    "for column in columns_to_impute:\n",
    "    median_value = df[column].median()\n",
    "    df[column].fillna(median_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d81e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for the maximum number of missing values allowed\n",
    "threshold = 250  # Adjust this threshold based on your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b67f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with a high number of missing values\n",
    "columns_to_drop = df.columns[df.isnull().sum() > threshold]\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0229dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of missing values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics for the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a878d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the style for the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Create a subplot of 1 row and 2 columns for box plot and histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=df['Weighted salary'])\n",
    "plt.title('Box plot of Weighted salary')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['Weighted salary'], kde=True, bins=30)\n",
    "plt.title('Histogram of Weighted salary')\n",
    "\n",
    "# Setting the style for the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Create a subplot of 1 row and 2 columns for box plot and histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=df['International Diversity'])\n",
    "plt.title('Box plot of International Diversity')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['International Diversity'], kde=True, bins=30)\n",
    "plt.title('Histogram of International Diversity')\n",
    "\n",
    "# Setting the style for the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Create a subplot of 1 row and 2 columns for box plot and histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=df['Salary percentage increase'])\n",
    "plt.title('Box plot of Salary percentage increase')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['Salary percentage increase'], kde=True, bins=30)\n",
    "plt.title('Histogram of Salary percentage increase')\n",
    "\n",
    "# Setting the style for the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Create a subplot of 1 row and 2 columns for box plot and histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=df['Faculty with doctorates (%)'])\n",
    "plt.title('Box plot of Faculty with doctorates (%)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['Faculty with doctorates (%)'], kde=True, bins=30)\n",
    "plt.title('Histogram of Faculty with doctorates (%)')\n",
    "\n",
    "# Setting the style for the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Create a subplot of 1 row and 2 columns for box plot and histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=df['Effective Emp rate'])\n",
    "plt.title('Box plot of Effective Emp rate')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['Effective Emp rate'], kde=True, bins=30)\n",
    "plt.title('Histogram of Effective Emp rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e3bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature correlations\n",
    "correlation_matrix = df.corr()\n",
    "correlations_with_target = correlation_matrix[\"#\"].sort_values(ascending=False)\n",
    "print(correlations_with_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10377da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate Analysis (Correlation Heatmap)\n",
    "corr_matrix = df.corr()\n",
    "plt.figure(figsize=(25, 15))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e382bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Replace the target variable and feature columns as needed\n",
    "target_column = \"#\"\n",
    "feature_columns = [ \"Weighted salary\"\n",
    ",\"Salary percentage increase\"           \n",
    ",\"Value for money rank\"                 \n",
    ",\"Career progress rank\"                                   \n",
    ",\"Aims achieved (%)\"                    \n",
    ",\"Effective Emp rate\"                   \n",
    ",\"International work mobility rank\"     \n",
    ",\"International course experience rank\" \n",
    ",\"Faculty with doctorates (%)\"                                                 \n",
    ",\"Internship\"                           \n",
    ",\"Overall Satisfaction\"                                                                     \n",
    ",\"International Diversity\"                            \n",
    ",\"GMAT/GRE Required\"\n",
    ",\"Female Empowerment Score\"\n",
    "]\n",
    "\n",
    "X = df[feature_columns]  # Features\n",
    "y = df[target_column]    # Target variable\n",
    "\n",
    "\n",
    "# Method 1: Random Forest\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X, y)\n",
    "feature_importance_rf = rf_model.feature_importances_\n",
    "\n",
    "# Method 2: XGBoost\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(X, y)\n",
    "feature_importance_xgb = xgb_model.feature_importances_\n",
    "\n",
    "# Display feature importance results for each method\n",
    "print(\"Feature Importance (Random Forest):\", feature_importance_rf)\n",
    "print(\"Feature Importance (XGBoost):\", feature_importance_xgb)\n",
    "\n",
    "# Visualize feature importances using bar plots\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(feature_importance_rf)), feature_importance_rf)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Feature Importance Score (Random Forest)')\n",
    "plt.title('Feature Importance Scores (Random Forest)')\n",
    "plt.xticks(range(len(feature_importance_rf)), feature_columns, rotation=90)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(feature_importance_xgb)), feature_importance_xgb)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Feature Importance Score (XGBoost)')\n",
    "plt.title('Feature Importance Scores (XGBoost)')\n",
    "plt.xticks(range(len(feature_importance_xgb)), feature_columns, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [ \"Weighted salary\"\n",
    ",\"Salary percentage increase\"           \n",
    ",\"Value for money rank\"                 \n",
    ",\"Career progress rank\"                 \n",
    "#,\"Career service rank\"                  \n",
    ",\"Aims achieved (%)\"                    \n",
    "#,\"Employed at three months (main)\"      \n",
    "#,\"Employed at three months (additional)\"\n",
    ",\"Effective Emp rate\"                   \n",
    "#,\"Female faculty (%)\"                   \n",
    ",\"Female students (%)\"                  \n",
    "#,\"Women on board (%)\"                  \n",
    "#,\"International faculty (%)\"            \n",
    "#,\"International students (%)\"           \n",
    "#,\"International board (%)\"              \n",
    ",\"International work mobility rank\"     \n",
    ",\"International course experience rank\" \n",
    ",\"Faculty with doctorates (%)\"          \n",
    "#,\"Three year average\"                                        \n",
    ",\"Internship\"                           \n",
    "#,\"Overall Satisfaction\"                                            \n",
    "#,\"No. of Students per Staff\"                         \n",
    ",\"International Diversity\"                            \n",
    "#,\"GMAT/GRE Required\"\n",
    "#,\"Female Empowerment Score\"\n",
    "]\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "X= df[metrics] \n",
    "y= df[\"#\"]\n",
    "\n",
    "# 2. Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Train Random Forest and SVM models\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "svm = SVR(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict on test data\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# 5. Calculate and print metrics\n",
    "metrics = {\n",
    "    \"MSE\": mean_squared_error,\n",
    "    \"MAE\": mean_absolute_error,\n",
    "    \"RMSE\": lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "    \"R^2\": r2_score\n",
    "}\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "for name, func in metrics.items():\n",
    "    print(f\"{name}: {func(y_test, y_pred_rf)}\")\n",
    "\n",
    "print(\"\\nSVM Metrics:\")\n",
    "for name, func in metrics.items():\n",
    "    print(f\"{name}: {func(y_test, y_pred_svm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a23f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already defined your X and y as features and target variable\n",
    "# If not, use X = df[metrics] and y = df[\"#\"] as you did in your previous code\n",
    "\n",
    "metrics = [ \"Weighted salary\"\n",
    ",\"Salary percentage increase\"           \n",
    ",\"Value for money rank\"                 \n",
    ",\"Career progress rank\"                                  \n",
    ",\"Aims achieved (%)\"                    \n",
    ",\"Effective Emp rate\"                                 \n",
    ",\"International work mobility rank\"     \n",
    ",\"International course experience rank\" \n",
    ",\"Faculty with doctorates (%)\"                                                  \n",
    ",\"Internship\"                           \n",
    ",\"Overall Satisfaction\"                                                                    \n",
    ",\"International Diversity\"                            \n",
    ",\"GMAT/GRE Required\"\n",
    ",\"Female Empowerment Score\"\n",
    "]\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "X= df[metrics] \n",
    "y= df[\"#\"]\n",
    "\n",
    "# 2. Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Create and train the Gradient Boosting Regressor model\n",
    "gb_regressor = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict on the test data\n",
    "y_pred_gb = gb_regressor.predict(X_test)\n",
    "\n",
    "# 5. Calculate and print regression metrics\n",
    "metrics = {\n",
    "    \"MSE\": mean_squared_error,\n",
    "    \"MAE\": mean_absolute_error,\n",
    "    \"RMSE\": lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "    \"R^2\": r2_score\n",
    "}\n",
    "\n",
    "print(\"Gradient Boosting Metrics:\")\n",
    "for name, func in metrics.items():\n",
    "    print(f\"{name}: {func(y_test, y_pred_gb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60685c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Simplified hyperparameter grid\n",
    "simple_param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3],\n",
    "    'gamma': [0, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Randomized search with cross-validation (fewer iterations for simplicity)\n",
    "xgb_simple_random_search = RandomizedSearchCV(xgb.XGBRegressor(objective ='reg:squarederror', random_state=42),\n",
    "                                              param_distributions=simple_param_grid, \n",
    "                                              n_iter=20, \n",
    "                                              scoring='neg_mean_squared_error', \n",
    "                                              cv=3, \n",
    "                                              verbose=1, \n",
    "                                              n_jobs=-1, \n",
    "                                              random_state=42)\n",
    "\n",
    "xgb_simple_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters from the simplified search\n",
    "simple_best_params = xgb_simple_random_search.best_params_\n",
    "simple_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Given training and testing sets: X_train, X_test, y_train, y_test\n",
    "\n",
    "# Train XGBoost with the optimal hyperparameters\n",
    "optimal_xgb = xgb.XGBRegressor(\n",
    "    subsample=0.8,\n",
    "    n_estimators=200,\n",
    "    min_child_weight=3,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    gamma=0.2,\n",
    "    colsample_bytree=0.8,\n",
    "    objective ='reg:squarederror',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "optimal_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_optimal = optimal_xgb.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse_optimal = mean_squared_error(y_test, y_pred_optimal)\n",
    "r2_optimal = r2_score(y_test, y_pred_optimal)\n",
    "mae_optimal = mean_absolute_error(y_test, y_pred_optimal)\n",
    "rmse_optimal = np.sqrt(mse_optimal)\n",
    "\n",
    "print(f\"MSE: {mse_optimal}\")\n",
    "print(f\"R^2: {r2_optimal}\")\n",
    "print(f\"MAE: {mae_optimal}\")\n",
    "print(f\"RMSE: {rmse_optimal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acbb71f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
